{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization using Bregman Divergenses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing NMF class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF as nmfsk\n",
    "from MatrixFactorization import NMF as nmfmy\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Testing General Rules vs Normal Ones (Poisson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Selecting best way to represent Poisson Distribution with Non- negative Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poission Distribution from definition does not take negative values since it is a discrete probability distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a19cfed68>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import scipy\n",
    "poisson = scipy.stats.distributions.poisson\n",
    "rs = RandomState(76321654)\n",
    "l = 5\n",
    "V = rs.poisson(lam = l, size = 10000).reshape(200,50)\n",
    "sns.set(color_codes=True)\n",
    "sns.distplot(V[4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Test NMF for Data coming from Poisson Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 14\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOG Likelihood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def neg_log_poisson(V,W,H):\n",
    "    logs_likelihoods = poisson.logpmf(V, np.rint(W.dot(H)))\n",
    "    neg_logs = - logs_likelihoods\n",
    "    inf_indices = np.where(neg_logs==float('inf'))\n",
    "    other = np.where(neg_logs != float('inf'))\n",
    "    neg_logs[inf_indices] = np.max(neg_logs[other])\n",
    "    return np.nansum(neg_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Implementation With Simple Update Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Neg Log Likelihood Between My Results and V :20999.308016373092\n"
     ]
    }
   ],
   "source": [
    "rs = RandomState(76321654)\n",
    "nmfM = nmfmy( n_components=n,random_state=rs, distribution = 'poisson')\n",
    "W1, H1 = nmfM.fit_transform(V)\n",
    "diffM = neg_log_poisson(V, W1, H1)\n",
    "print('Neg Log Likelihood Between My Results and V :' + str(diffM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Implementation With General Update Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Neg Log Likelihood Between My Results and V :0.0\n"
     ]
    }
   ],
   "source": [
    "rs = RandomState(76321654)\n",
    "nmfM = nmfmy( n_components=n,random_state=rs, distribution = 'poisson',phi_update = True)\n",
    "W, H = nmfM.fit_transform(V)\n",
    "diffM = neg_log_poisson(V, W, H)\n",
    "print('Neg Log Likelihood Between My Results and V :' + str(diffM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the three Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py:241: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py:241: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py:241: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py:241: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "/Users/michailkoupparis/Desktop/MatrixTensorFactorization/MatrixFactorization/NMF.py:35: RuntimeWarning: overflow encountered in power\n",
      "  H = np.multiply(H, np.power(math.e, np.divide(W.T.dot(np.log(Vc)),W.T.dot(np.log(W.dot(H))))))\n",
      "/Users/michailkoupparis/Desktop/MatrixTensorFactorization/MatrixFactorization/NMF.py:36: RuntimeWarning: invalid value encountered in true_divide\n",
      "  W = np.multiply ( W, np.power(math.e, np.divide( ((np.log(Vc))).dot(H.T) , np.log(W.dot(H)).dot(H.T)    )  ))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c0d4cda6caf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0merrorsSimple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiffS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mdiffS2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWGeneral\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHGeneral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0merrorsGeneral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiffS2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \"\"\"\n\u001b[1;32m    238\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 239\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 568\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "errorsSimple = np.zeros(50)\n",
    "errorsGeneral = np.zeros(50)\n",
    "\n",
    "lsSimple = np.zeros(50)\n",
    "lsGeneral = np.zeros(50)\n",
    "\n",
    "\n",
    "\n",
    "for n in range(1, 51):\n",
    "    rs = RandomState(76321654)\n",
    "    \n",
    "   \n",
    "   \n",
    "    #My Simple\n",
    "    rs = RandomState(76321654)\n",
    "    nmfSimple = nmfmy(n_components=n,random_state=rs,  distribution = 'poisson')\n",
    "    WSimple, HSimple = nmfSimple.fit_transform(V)\n",
    "    \n",
    "    # My with General\n",
    "    rs = RandomState(76321654)\n",
    "    nmfGeneral = nmfmy(n_components=n,random_state=rs,  distribution = 'poisson',phi_update = True)\n",
    "    WGeneral, HGeneral = nmfGeneral.fit_transform(V)\n",
    "   \n",
    "  \n",
    "    \n",
    "    # Mean Squared Errors\n",
    "    diffS = mean_squared_error(V, WSimple.dot(HSimple))\n",
    "    errorsSimple[n-1] = diffS\n",
    "    \n",
    "    diffS2 = mean_squared_error(V, WGeneral.dot(HGeneral))\n",
    "    errorsGeneral[n-1] = diffS2\n",
    "    \n",
    "    \n",
    "    # Average Negative log likelihood\n",
    "    diffS = neg_log_poisson(V, WSimple, HSimple)\n",
    "    lsSimple[n-1] = diffS / (V.shape[0] * V.shape[1])\n",
    "    \n",
    "    diffS2 = neg_log_poisson(V, WGeneral, HGeneral)\n",
    "    lsGeneral[n-1] = diffS2 / (V.shape[0] * V.shape[1])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1 = plt.figure(figsize=(16, 10))\n",
    "ax_1 = fig_1.add_subplot(111)\n",
    "    \n",
    "ax_1.plot(np.arange(1, 51), \n",
    "                  errorsSimple, label=\"Simple\")\n",
    "ax_1.plot(np.arange(1, 51), \n",
    "                  errorsGeneral, label=\"General\")\n",
    "\n",
    "ax_1.legend(loc=0)\n",
    "\n",
    "ax_1.set_xlabel('N components')\n",
    "ax_1.set_ylabel('Mean Squared Error')\n",
    "fig_1.suptitle('Mean Squared Errors for Poisson Distribution')\n",
    "fig_1.savefig('MeanSquaredErrorsForNMFPoissonCompareSimpleGeneral.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1 = plt.figure(figsize=(16, 10))\n",
    "ax_1 = fig_1.add_subplot(111)\n",
    "    \n",
    "ax_1.plot(np.arange(1, 51), \n",
    "                  lsSimple, label=\"Simple\")\n",
    "ax_1.plot(np.arange(1, 51), \n",
    "                  lsGeneral, label=\"General\")\n",
    "\n",
    "ax_1.legend(loc=0)\n",
    "\n",
    "ax_1.set_xlabel('N components')\n",
    "ax_1.set_ylabel('Avg Negative Log Likelihood')\n",
    "fig_1.suptitle('Avg Negative Log Likelihood for Poisson Distribution CDF')\n",
    "fig_1.savefig('AverageNegLogLikelihoodForNMFPoissonCompareSimpleGeneral.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution compared to Mine with 10 components and Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomState(76321654)\n",
    "nmfM = nmfmy(n_components=n,random_state=rs, distribution = 'poisson')\n",
    "W, H = nmfM.fit_transform(V)\n",
    "bins = (V.max() - V.min())\n",
    "sns.set(color_codes=True)\n",
    "sns.distplot(V[10],  label = 'V')\n",
    "sns.distplot(W.dot(H)[10],  label = 'Simple')\n",
    "plt.legend()\n",
    "print('Original Data mean: ' + str(V.mean()) + ' std: ' + str(V.std()) )\n",
    "print('Tansformation Data : ' + str(W.dot(H).mean()) + ' std: ' + str(W.dot(H).std()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution compared to Mine with 10 components with Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomState(76321654)\n",
    "nmfM = nmfmy(n_components=n,random_state=rs, distribution = 'poisson', phi_update = True)\n",
    "W, H = nmfM.fit_transform(V)\n",
    "bins = (V.max() - V.min())\n",
    "sns.set(color_codes=True)\n",
    "sns.distplot(V[10],  label = 'V')\n",
    "sns.distplot(W.dot(H)[10],  label = 'PHi')\n",
    "plt.legend()\n",
    "print('Original Data mean: ' + str(V.mean()) + ' std: ' + str(V.std()) )\n",
    "print('Tansformation Data : ' + str(W.dot(H).mean()) + ' std: ' + str(W.dot(H).std()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "n = 10\n",
    "i = 0\n",
    "max_ts = [200,1000,2000,4000,8000,16000,32000,40000]\n",
    "errorsSimple = np.zeros(len(max_ts))\n",
    "errorsGeneral = np.zeros(len(max_ts))\n",
    "\n",
    "lsSimple = np.zeros(len(max_ts))\n",
    "lsGeneral = np.zeros(len(max_ts))\n",
    "\n",
    "for max_it in max_ts:\n",
    "    rs = RandomState(76321654)\n",
    "    \n",
    "   \n",
    "   \n",
    "    #My Simple\n",
    "    rs = RandomState(76321654)\n",
    "    nmfSimple = nmfmy(max_iterations = max_it, n_components=n,random_state=rs,  distribution = 'poisson')\n",
    "    WSimple, HSimple = nmfSimple.fit_transform(V)\n",
    "    \n",
    "    # My with General\n",
    "    rs = RandomState(76321654)\n",
    "    nmfGeneral = nmfmy(max_iterations = max_it, n_components=n,random_state=rs,  distribution = 'poisson',phi_update = True)\n",
    "    WGeneral, HGeneral = nmfGeneral.fit_transform(V)\n",
    "   \n",
    "  \n",
    "    \n",
    "    # Mean Squared Errors\n",
    "    diffS = mean_squared_error(V, WSimple.dot(HSimple))\n",
    "    errorsSimple[i] = diffS\n",
    "    \n",
    "    diffS2 = mean_squared_error(V, WGeneral.dot(HGeneral))\n",
    "    errorsGeneral[i] = diffS2\n",
    "    \n",
    "    \n",
    "    # Average Negative log likelihood\n",
    "    diffS = neg_log_poisson(V, WSimple, HSimple)\n",
    "    lsSimple[i] = diffS / (V.shape[0] * V.shape[1])\n",
    "    \n",
    "    diffS2 = neg_log_poisson(V, WGeneral, HGeneral)\n",
    "    lsGeneral[i] = diffS2 / (V.shape[0] * V.shape[1])\n",
    "    \n",
    "    print('MAX ITERATIONS :' + str(max_it))\n",
    "    print(\"Mean Squared Error For Simple : \" +  str(errorsSimple[i]))\n",
    "    print(\"Mean Squared Error For Genearal : \" +  str(errorsGeneral[i]))\n",
    "    print(\"Average Negative Log Likelihood for Simple : \" +  str(lsSimple[i]))\n",
    "    print(\"Average Negative Log Likelihood for General : \" +  str(lsGeneral[i]))\n",
    "    i += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1 = plt.figure(figsize=(16, 10))\n",
    "ax_1 = fig_1.add_subplot(111)\n",
    "    \n",
    "ax_1.plot(max_ts, \n",
    "                  lsSimple, label=\"Simple\")\n",
    "ax_1.plot(max_ts, \n",
    "                  lsGeneral, label=\"General\")\n",
    "\n",
    "ax_1.legend(loc=0)\n",
    "\n",
    "ax_1.set_xlabel('Max Iteration')\n",
    "ax_1.set_ylabel('Avg Negative Log Likelihood')\n",
    "fig_1.suptitle('Avg Negative Log Likelihood for Poisson Distribution with 10 components')\n",
    "fig_1.savefig('AverageNegLogLikelihoodForNMFPoissonCompareSimpleGeneralMaxIts.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
