{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization using Bregman Divergenses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing NMF class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF as nmfsk\n",
    "from MatrixFactorization import NMF as nmfmy\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Poisson Distribution (with kullback-leibler as the Divergense Function To be Minimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Selecting best way to represent Poisson Distribution with Non- negative Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poission Distribution from definition does not take negative values since it is a discrete probability distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1a0720f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "rs = RandomState(76321654)\n",
    "l = 2\n",
    "V = rs.poisson(lam = l, size = 10000).reshape(200,50)\n",
    "sns.set(color_codes=True)\n",
    "sns.distplot(V[4],  bins=np.arange(V[4].min(),V[4].max()) * l, hist_kws=dict(ec=\"k\"), label = 'V')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Test NMF for Data coming from Poisson Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "n = 14\n",
    "poisson = scipy.stats.distributions.poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOG Likelihood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def neg_log_poisson(V,W,H):\n",
    "    logs_likelihoods = poisson.logpmf(V, np.rint(W.dot(H)))\n",
    "    neg_logs = - logs_likelihoods\n",
    "    inf_indices = np.where(neg_logs==float('inf'))\n",
    "    other = np.where(neg_logs != float('inf'))\n",
    "    neg_logs[inf_indices] = np.max(neg_logs[other])\n",
    "    return np.nansum(neg_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg Log Likelihood Between Sklearn Results and V :15615.541377654807\n"
     ]
    }
   ],
   "source": [
    "rs = RandomState(76321654)\n",
    "nmfS = nmfsk(n_components=n,random_state=rs,solver='mu', beta_loss='kullback-leibler' )\n",
    "Ws = nmfS.fit_transform(V)\n",
    "Hs = nmfS.components_\n",
    "\n",
    "diffS = neg_log_poisson(V, Ws, Hs)\n",
    "print('Neg Log Likelihood Between Sklearn Results and V :' + str(diffS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg Log Likelihood Between My Results and V :22128.654586311655\n"
     ]
    }
   ],
   "source": [
    "rs = RandomState(76321654)\n",
    "nmfM = nmfmy( n_components=n,random_state=rs, distribution = 'poisson')\n",
    "W, H = nmfM.fit_transform(V)\n",
    "diffM = neg_log_poisson(V, W, H)\n",
    "print('Neg Log Likelihood Between My Results and V :' + str(diffM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Implementation Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomState(76321654)\n",
    "nmfM = nmfmy(n_components=n,random_state=rs, distribution = 'gaussian')\n",
    "W, H = nmfM.fit_transform(V)\n",
    "diffM = neg_log_poisson(V, W, H)\n",
    "print('Neg Log Likelihood Between My Results and V :' + str(diffM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination of My and Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MatrixFactorization import myNMF as nmfmy2\n",
    "rs = RandomState(76321654)\n",
    "nmfM2 = nmfmy2(n_components=n,random_state=rs, distribution = 'poisson')\n",
    "W2 = nmfM2.fit_transform(V)\n",
    "H2 = nmfM2.components_\n",
    "\n",
    "diffM2 =neg_log_poisson(V, W2, H2)\n",
    "print('Neg Log Likelihood Between My Results and V :' + str(diffM2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the three Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorssk = np.zeros(50)\n",
    "errorssk2 = np.zeros(50)\n",
    "errorsmy = np.zeros(50)\n",
    "errorsmy2 = np.zeros(50)\n",
    "\n",
    "lsk = np.zeros(50)\n",
    "lsk2 = np.zeros(50)\n",
    "lmy = np.zeros(50)\n",
    "lmy2 = np.zeros(50)\n",
    "\n",
    "\n",
    "\n",
    "# Compare with normal \n",
    "errorsmyNormal = np.zeros(50)\n",
    "lmyNormal = np.zeros(50)\n",
    "\n",
    "for n in range(1, 51):\n",
    "    rs = RandomState(76321654)\n",
    "    \n",
    "    # Sklearn\n",
    "    nmfS = nmfsk(n_components=n,random_state=rs)\n",
    "    Ws = nmfS.fit_transform(V)\n",
    "    Hs = nmfS.components_\n",
    "    \n",
    "    # Sklearn with kullback-leibler\n",
    "    rs = RandomState(76321654)\n",
    "    nmfS2 = nmfsk(n_components=n,random_state=rs,  solver='mu', beta_loss='kullback-leibler')\n",
    "    Ws2 = nmfS2.fit_transform(V)\n",
    "    Hs2 = nmfS2.components_\n",
    "\n",
    "    \n",
    "    \n",
    "    #My \n",
    "    rs = RandomState(76321654)\n",
    "    nmfM = nmfmy(n_components=n,random_state=rs,  distribution = 'poisson')\n",
    "    W, H = nmfM.fit_transform(V)\n",
    "    \n",
    "    # My with Normal\n",
    "    rs = RandomState(76321654)\n",
    "    nmfMNormal = nmfmy(n_components=n,random_state=rs,  distribution = 'gaussian')\n",
    "    Wnormal, Hnormal = nmfMNormal.fit_transform(V)\n",
    "   \n",
    "    \n",
    "    #Combination\n",
    "    rs = RandomState(76321654)\n",
    "    nmfM2 = nmfmy2(n_components=n,random_state=rs, distribution = 'poisson')\n",
    "    W2 = nmfM2.fit_transform(V)\n",
    "    H2 = nmfM2.components_\n",
    "    \n",
    "    \n",
    "    # Mean Squared Errors\n",
    "    diffS = mean_squared_error(V, Ws.dot(Hs))\n",
    "    errorssk[n-1] = diffS\n",
    "    \n",
    "    diffS2 = mean_squared_error(V, Ws2.dot(Hs2))\n",
    "    errorssk2[n-1] = diffS2\n",
    "    \n",
    "    diffM = mean_squared_error(V, W.dot(H))\n",
    "    errorsmy[n-1] = diffM\n",
    "    \n",
    "    diffMnormal = mean_squared_error(V, Wnormal.dot(Hnormal))\n",
    "    errorsmyNormal[n-1] = diffMnormal\n",
    "    \n",
    "    diffM2 =mean_squared_error(V, W2.dot(H2))\n",
    "    errorsmy2[n-1] = diffM2\n",
    "    \n",
    "    # Average Negative log likelihood\n",
    "    diffS = neg_log_poisson(V, Ws, Hs)\n",
    "    lsk[n-1] = diffS / (V.shape[0] * V.shape[1])\n",
    "    \n",
    "    diffS2 = neg_log_poisson(V, Ws2, Hs2)\n",
    "    lsk2[n-1] = diffS2 / (V.shape[0] * V.shape[1])\n",
    "    \n",
    "    diffM = neg_log_poisson(V, W, H)\n",
    "    lmy[n-1] = diffM / (V.shape[0] * V.shape[1])\n",
    "    \n",
    "    diffMNormal = neg_log_poisson(V, Wnormal, Hnormal)\n",
    "    lmyNormal[n-1] = diffMNormal / (V.shape[0] * V.shape[1])\n",
    "    \n",
    "    diffM2 = neg_log_poisson(V, W2 , H2)\n",
    "    lmy2[n-1] = diffM2 / (V.shape[0] * V.shape[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1 = plt.figure(figsize=(16, 10))\n",
    "ax_1 = fig_1.add_subplot(111)\n",
    "    \n",
    "ax_1.plot(np.arange(1, 51), \n",
    "                  errorssk, label=\"Sklearn Forb\")\n",
    "ax_1.plot(np.arange(1, 51), \n",
    "                  errorssk2, label=\"Sklearn KL\")\n",
    "ax_1.plot(np.arange(1, 51), \n",
    "                  errorsmy, label=\"Mine Poisson\")\n",
    "ax_1.plot(np.arange(1, 51), \n",
    "                  errorsmyNormal, label=\"Mine Normal\")\n",
    "ax_1.plot(np.arange(1, 51), \n",
    "                  errorsmy2, label=\"Combination\")\n",
    "ax_1.legend(loc=0)\n",
    "\n",
    "ax_1.set_xlabel('N components')\n",
    "ax_1.set_ylabel('Mean Squared Error')\n",
    "fig_1.suptitle('Mean Squared Errors for Poisson Distribution')\n",
    "fig_1.savefig('MeanSquaredErrorsForNMFPoisson1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1 = plt.figure(figsize=(16, 10))\n",
    "ax_1 = fig_1.add_subplot(111)\n",
    "    \n",
    "ax_1.plot(np.arange(1, 51), \n",
    "                  lsk, label=\"Sklearn Forb\")\n",
    "ax_1.plot(np.arange(1, 51), \n",
    "                  lsk2, label=\"Sklearn KL\")\n",
    "ax_1.plot(np.arange(1, 51), \n",
    "                  lmy, label=\"Mine Poisson\")\n",
    "ax_1.plot(np.arange(1, 51), \n",
    "                  lmyNormal, label=\"Mine Normal\")\n",
    "ax_1.plot(np.arange(1, 51), \n",
    "                  lmy2, label=\"Combination\")\n",
    "ax_1.legend(loc=0)\n",
    "\n",
    "ax_1.set_xlabel('N components')\n",
    "ax_1.set_ylabel('Avg Negative Log Likelihood')\n",
    "fig_1.suptitle('Avg Negative Log Likelihood for Poisson Distribution CDF')\n",
    "fig_1.savefig('AverageNegLogLikelihoodForNMFPoisson1CDF.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution compared to Sklearn with 10 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomState(76321654)\n",
    "nmfS = nmfsk(n_components=n,random_state=rs)\n",
    "Ws = nmfS.fit_transform(V)\n",
    "Hs = nmfS.components_\n",
    "sns.set(color_codes=True)\n",
    "sns.distplot(V[10], bins=np.arange(V[10].min(),V[10].max()) * l, hist_kws=dict(ec=\"k\"), label = 'V')\n",
    "sns.distplot(Ws.dot(Hs)[10], bins=np.arange(V[10].min(),V[10].max()) * l, hist_kws=dict(ec=\"k\"), label = 'Sklearn')\n",
    "plt.legend()\n",
    "print('Original Data mean: ' + str(V.mean()) + ' std: ' + str(V.std()) )\n",
    "print('Tansformation Data : ' + str(Ws.dot(Hs).mean()) + ' std: ' + str(Ws.dot(Hs).std()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution compared to Mine with 10 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomState(76321654)\n",
    "nmfM = nmfmy(n_components=n,random_state=rs, distribution = 'poisson')\n",
    "W, H = nmfM.fit_transform(V)\n",
    "bins = (V.max() - V.min())\n",
    "sns.set(color_codes=True)\n",
    "sns.distplot(V[10], bins=np.arange(V[10].min(),V[10].max()) * l, hist_kws=dict(ec=\"k\"),  label = 'V')\n",
    "sns.distplot(W.dot(H)[10], bins=np.arange(V[10].min(),V[10].max()) * l, hist_kws=dict(ec=\"k\"),  label = 'Mine')\n",
    "plt.legend()\n",
    "print('Original Data mean: ' + str(V.mean()) + ' std: ' + str(V.std()) )\n",
    "print('Tansformation Data : ' + str(W.dot(H).mean()) + ' std: ' + str(W.dot(H).std()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution compared to Mine with 10 components with Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomState(76321654)\n",
    "nmfM = nmfmy(n_components=n,random_state=rs, distribution = 'gaussian')\n",
    "W, H = nmfM.fit_transform(V)\n",
    "bins = (V.max() - V.min())\n",
    "sns.set(color_codes=True)\n",
    "sns.distplot(V[10], bins=np.arange(V[10].min(),V[10].max()) * l, hist_kws=dict(ec=\"k\"),  label = 'V')\n",
    "sns.distplot(W.dot(H)[10], bins=np.arange(V[10].min(),V[10].max()) * l, hist_kws=dict(ec=\"k\"), label = 'Mine')\n",
    "plt.legend()\n",
    "print('Original Data mean: ' + str(V.mean()) + ' std: ' + str(V.std()) )\n",
    "print('Tansformation Data : ' + str(W.dot(H).mean()) + ' std: ' + str(W.dot(H).std()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution compared to Combination with 10 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MatrixFactorization import myNMF as nmfmy2\n",
    "rs = RandomState(76321654)\n",
    "nmfM2 = nmfmy2(n_components=n,random_state=rs, distribution = 'poisson')\n",
    "W2 = nmfM2.fit_transform(V)\n",
    "H2 = nmfM2.components_\n",
    "sns.set(color_codes=True)\n",
    "sns.distplot(V[10],bins=np.arange(V[10].min(),V[10].max()) * l, hist_kws=dict(ec=\"k\"), label = 'V')\n",
    "sns.distplot(W2.dot(H2)[10], bins=np.arange(V[10].min(),V[10].max()) * l, hist_kws=dict(ec=\"k\"), label = 'Combination')\n",
    "plt.legend()\n",
    "print('Original Data mean: ' + str(V.mean()) + ' std: ' + str(V.std()) )\n",
    "print('Tansformation Data : ' + str(W2.dot(H2).mean()) + ' std: ' + str(W2.dot(H2).std()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
